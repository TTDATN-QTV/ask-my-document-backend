# Ask My Document - Backend MVP

·ª®ng d·ª•ng h·ªèi ƒë√°p t√†i li·ªáu PDF s·ª≠ d·ª•ng **RAG (Retrieval Augmented Generation)** v√† **LLM local** (.bin).  
Ng∆∞·ªùi d√πng c√≥ th·ªÉ upload t√†i li·ªáu PDF, h·ªá th·ªëng s·∫Ω tr√≠ch xu·∫•t d·ªØ li·ªáu, l∆∞u v√†o FAISS v√† tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n n·ªôi dung t√†i li·ªáu.

---

## üöÄ C√†i ƒë·∫∑t

```bash
# Clone d·ª± √°n
git clone https://github.com/TTDATN-QTV/ask-my-document-backend.git
cd ask-my-document-backend

# T·∫°o virtual environment
python -m venv .venv
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
.venv\Scripts\activate

# C·∫≠p nh·∫≠t pip v√† c√†i ƒë·∫∑t dependencies
python -m pip install --upgrade pip
pip install -r requirements.txt
```

## ‚ö°Ô∏è Ch·∫°y Backend (FastAPI)

```bash
uvicorn app.main:app --reload
```

Truy c·∫≠p API docs t·∫°i: http://127.0.0.1:8000/docs

## üñ•Ô∏è Ch·∫°y giao di·ªán MVP (Streamlit)

```bash
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
.venv\Scripts\activate
python -m streamlit run mvp_ui/main.py
```

## üì• T·∫£i LLM v√† d·ªØ li·ªáu m·∫´u
- T·∫£i LLM (GGML .bin): `https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main`
- T·∫£i file PDF m·∫´u: `https://drive.google.com/drive/folders/1_0JWnoLTJsbmswUGs5z1ULd7u4fqfzEf?usp=drive_link`

## üîÄ ƒê·ªïi LLM kh√°c
Khi mu·ªën ƒë·ªïi sang LLM kh√°c:
- T·∫£i GGML .bin v·ªÅ v√® ƒë·∫∑t trong th∆∞ ·ª•c models/ t·∫°i th∆∞ m·ª•c g·ªëc.
- Thay `model_path` trong file `app/utils/llm_client.py`

```python
# Existing code...

class LocalLLM:
    def __init__(self, model_path="models/llama-2-7b-chat.ggmlv3.q4_1.bin"): # <-- Thay model_path t·∫°i ƒë√¢y
        self.llm = CTransformers(
            model=model_path,
            model_type="llama",
            config={
                "max_new_tokens": 256,
                "temperature": 0.01
            }
        )

# Existing code...
```


## üìÇ C·∫•u tr√∫c th∆∞ m·ª•c
```
ask-my-document-backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ upload.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query.py
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat_service.py
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_client.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ uploads/
‚îÇ   ‚îî‚îÄ‚îÄ index/
‚îÇ
‚îú‚îÄ‚îÄ fonts/
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ llama-2-7b-chat.ggmlv3.q4_1.bin
‚îÇ
‚îú‚îÄ‚îÄ mvp_ui/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ make_sample_pdf.py
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_rag_pipeline.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_retriever.py
‚îÇ   ‚îú‚îÄ‚îÄ resources/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample.pdf
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_upload.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_query.py
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_document_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_chat_service.py
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ build_mock_index.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_llm_client.py
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

## ‚ú® Ch·ª©c nƒÉng

- üìÑ Upload t√†i li·ªáu PDF.
- üîé T√°ch vƒÉn b·∫£n, chia nh·ªè theo ƒëo·∫°n.
- üì¶ L∆∞u embedding v√†o FAISS ƒë·ªÉ truy v·∫•n nhanh.
- üí¨ H·ªèi ƒë√°p v·ªõi LLM local (s·ª≠ d·ª•ng m√¥ h√¨nh .bin).
- üåê REST API (FastAPI) + Giao di·ªán MVP (Streamlit).
- ‚öôÔ∏è H·ªó tr·ª£ nhi·ªÅu t√†i li·ªáu, metadata theo d√µi context.
- üöÄ D·ªÖ m·ªü r·ªông sang Hugging Face API ho·∫∑c LLM kh√°c.

## üîÆ ƒê·ªãnh h∆∞·ªõng ph√°t tri·ªÉn

- H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng t√†i li·ªáu (DOCX, TXT, Markdown).
- T√≠ch h·ª£p x√°c th·ª±c ng∆∞·ªùi d√πng & ph√¢n quy·ªÅn.
- T√≠ch h·ª£p microservice + frontend ri√™ng bi·ªát.
- Th√™m ch·ª©c nƒÉng t√¨m ki·∫øm ƒëa t√†i li·ªáu.
